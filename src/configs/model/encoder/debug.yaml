defaults:
  - base

embedding_dim: 10

graph_stack_config:
  num_layers: 2
  ffn_embedding_dim: 20
  num_attention_heads: 1

# 1 fusion stack with 2 layers
num_fusion_stack: 1
fusion_stack_size: 2

text_model_config:
  test_config:
    _target_: transformers.BertConfig
    hidden_size: 10
    intermediate_size: 20
    vocab_size: 10
    max_position_embeddings: 20
    num_hidden_layers: 4
    num_attention_heads: 1

vit_model_config:
  # L=12, A=2, H=224
  test_config:
    _target_: transformers.ViTConfig
    hidden_size: 10
    intermediate_size: 20
    image_size: 100
    patch_size: 10
    encoder_stride: 10
    num_hidden_layers: 4
    num_attention_heads: 1

num_bottle_neck: 2

freeze_initial_encoders: True
