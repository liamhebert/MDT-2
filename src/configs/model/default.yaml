defaults:
  - loss: cross_entropy
  - encoder: base_v2

_target_: model.Model

optimizer:
  _target_: torch.optim.AdamW
  _partial_: true
  lr: 0.001
  weight_decay: 0.0
  betas: [0.9, 0.95]

scheduler:
  _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  _partial_: true
  mode: min
  factor: 0.1
  patience: 3

# compile model for faster training with pytorch 2.0
compile: False
